{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets\n",
    "============================\n",
    "\n",
    "Datasets tell PHOEBE how and at what times to compute the model.  In some cases these will include the actual observational data, and in other cases may only include the times at which you want to compute a synthetic model.\n",
    "\n",
    "Adding a dataset - even if it doesn't contain any observational data - is required in order to compute a synthetic model (which will be described in the following [Compute Tutorial](compute.ipynb)).\n",
    "\n",
    "Setup\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first make sure we have the latest version of PHOEBE 2.2 installed. (You can comment out this line if you don't use pip for your installation or don't want to update to the latest release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -I \"phoebe>=2.2,<2.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As always, let's do imports and initialize a logger and a new Bundle.  See [Building a System](building_a_system.ipynb) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoebe\n",
    "from phoebe import u # units\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logger = phoebe.logger()\n",
    "\n",
    "b = phoebe.default_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a Dataset from Arrays\n",
    "--------------------------------------\n",
    "\n",
    "To add a dataset, you need to provide the function in\n",
    "[phoebe.parameters.dataset](../api/phoebe.parameters.dataset.md) for the particular type of data you're dealing with, as well\n",
    "as any of your \"observed\" arrays.\n",
    "\n",
    "The current available methods include:\n",
    "\n",
    "* [lc](../api/phoebe.parameters.dataset.lc.md) light curves ([tutorial](LC.ipynb))\n",
    "* [rv](../api/phoebe.parameters.dataset.rv.md) radial velocity curves ([tutorial](RV.ipynb))\n",
    "* [lp](../api/phoebe.parameters.dataset.lp.md) spectral line profiles ([tutorial](LP.ipynb))\n",
    "* [orb](../api/phoebe.parameters.dataset.orb.md) orbit/positional data ([tutorial](ORB.ipynb))\n",
    "* [mesh](../api/phoebe.parameters.dataset.mesh.md) discretized mesh of stars ([tutorial](MESH.ipynb))\n",
    "\n",
    "### Without Observations\n",
    "\n",
    "The simplest case of adding a dataset is when you do not have observational \"data\" and only want to compute a synthetic model.  Here all you need to provide is an array of times and information about the type of data and how to compute it.\n",
    "\n",
    "This situation will almost always be the case for orbits and meshes - its unlikely that you have observed positions and velocities for each of your components, but you still may like to store that information for plotting or diagnostic purposes.\n",
    "\n",
    "Here we'll do just that - we'll add an orbit dataset which will track the positions and velocities of both our 'primary' and 'secondary' stars (by their component tags) at each of the provided times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 6 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset(phoebe.dataset.orb, \n",
    "              times=np.linspace(0,10,20), \n",
    "              dataset='orb01', \n",
    "              component=['primary', 'secondary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you could probably predict by now, [add_dataset](../api/phoebe.frontend.bundle.Bundle.add_dataset.md)  can either take a function or the name of a function in [phoebe.parameters.dataset](../api/phoebe.parameters.dataset.md).  The following line would do the same thing (and we'll pass `overwrite=True` to avoid the error of overwriting dataset='orb01')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 6 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('orb', \n",
    "              times=np.linspace(0,10,20), \n",
    "              component=['primary', 'secondary'], \n",
    "              dataset='orb01', \n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that add_dataset does take some time to complete.  In the background, the passband is being loaded (when applicable) and many parameters are created and attached to the Bundle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not provide a list of component(s), they will be assumed for you based on the dataset method.  Light curves and meshes can only attach at the system level (component=None), for instance, whereas RVs and ETVs can attach for each star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 18 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('rv', times=np.linspace(0,10,20), dataset='rv01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['primary', 'secondary']\n"
     ]
    }
   ],
   "source": [
    "print(b.filter(qualifier='times', dataset='rv01').components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we added an RV dataset and can see that it was automatically created for both stars in our system.  Under-the-hood, another entry is created for component='\\_default'.  The default parameters hold the values that will be replicated if a new component is added to the system in the future.  In order to see these hidden parameters, you need to pass check_default=False to any filter-type call (and note that '\\_default' is no longer exposed when calling `.components`).  Also note that for set_value_all, this is automatically set to False.\n",
    "\n",
    "Since we did not explicitly state that we only wanted the primary and secondary components, the time array on '\\_default' is filled as well.  If we were then to add a tertiary component, its RVs would automatically be computed because of this replicated time array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['primary', 'secondary']\n"
     ]
    }
   ],
   "source": [
    "print(b.filter(qualifier='times', dataset='rv01', check_default=False).components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: times@_default@rv01@rv@dataset\n",
      "                       Qualifier: times\n",
      "                     Description: Observed times\n",
      "                           Value: [ 0.          0.52631579  1.05263158 ...  8.94736842  9.47368421\n",
      " 10.        ] d\n",
      "                  Constrained by: \n",
      "                      Constrains: None\n",
      "                      Related to: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(b.get('times@_default@rv01', check_default=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 'orb' datasets defined earlier, on the other hand, we explicitly provided components.  In that case the '\\_default' times will be empty - adding a new component will result in this empty array being replicated and the orbit will NOT be computed for the tertiary component.  Of course, you could always manually copy the time array at a later time if you wanted the orbit to be computed.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: times@_default@orb01@orb@dataset\n",
      "                       Qualifier: times\n",
      "                     Description: Observed times\n",
      "                           Value: [] d\n",
      "                  Constrained by: \n",
      "                      Constrains: None\n",
      "                      Related to: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(b.get('times@_default@orb01', check_default=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Observations\n",
    "\n",
    "Loading datasets with observations is (nearly) as simple.  \n",
    "\n",
    "Passing arrays to any of the dataset columns will apply it to all of the same components in which the time will be applied (see the 'Without Observations' section above for more details).  This make perfect sense for fluxes in light curves where the time and flux arrays are both at the system level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 20 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('lc', times=[0,1], fluxes=[1,0.5], dataset='lc01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: fluxes@lc01@dataset\n",
      "                       Qualifier: fluxes\n",
      "                     Description: Observed flux\n",
      "                           Value: [1.  0.5] W / m2\n",
      "                  Constrained by: \n",
      "                      Constrains: None\n",
      "                      Related to: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(b['fluxes@lc01@dataset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For datasets which attach to individual components, however, this isn't always the desired behavior.\n",
    "\n",
    "For a single-lined RV where we only attach to one component, everything is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 16 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('rv', \n",
    "              times=[0,1], \n",
    "              rvs=[-3,3], \n",
    "              component='primary', \n",
    "              dataset='rv01', \n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: rvs@primary@rv01@dataset\n",
      "                       Qualifier: rvs\n",
      "                     Description: Observed radial velocity\n",
      "                           Value: [-3.  3.] km / s\n",
      "                  Constrained by: \n",
      "                      Constrains: None\n",
      "                      Related to: None\n",
      "                 Only visible if: times:<notempty>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(b['rvs@rv01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for a double-lined RV we probably **don't** want to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 18 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('rv', \n",
    "              times=[0,1], \n",
    "              rvs=[-3,3], \n",
    "              dataset='rv02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterSet: 2 parameters\n",
      "        rvs@primary@rv02@dataset: [-3.  3.] km / s\n",
      "      rvs@secondary@rv02@dataset: [-3.  3.] km / s\n"
     ]
    }
   ],
   "source": [
    "print(b['rvs@rv02'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead we want to pass different arrays to the 'rvs@primary' and 'rvs@secondary'.  This can be done by explicitly stating the components in a dictionary sent to that argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 18 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('rv', \n",
    "              times=[0,1], \n",
    "              rvs={'primary': [-3,3], 'secondary': [4,-4]}, \n",
    "              dataset='rv02',\n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterSet: 2 parameters\n",
      "        rvs@primary@rv02@dataset: [-3.  3.] km / s\n",
      "      rvs@secondary@rv02@dataset: [ 4. -4.] km / s\n"
     ]
    }
   ],
   "source": [
    "print(b['rvs@rv02'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you could of course not pass the values while calling add_dataset and instead call the set_value method after and explicitly state the components at that time.  For more details see the [add_dataset API docs](../api/phoebe.frontend.bundle.Bundle.add_dataset.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Passband Options\n",
    "\n",
    "Passband options follow the exact same rules as dataset columns.\n",
    "\n",
    "Sending a single value to the argument will apply it to *each* component in which the time array is attached (either based on the list of components sent or the defaults from the dataset method).\n",
    "\n",
    "Note that for light curves, in particular, this rule gets slightly bent.  The dataset arrays for light curves are attached at the system level, *always*.  The passband-dependent options, however, exist for each star in the system.  So, that value will get passed to each star if the component is not explicitly provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 22 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('lc', \n",
    "              times=[0,1], \n",
    "              ld_func='logarithmic', \n",
    "              dataset='lc01', \n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: times@lc01@dataset\n",
      "                       Qualifier: times\n",
      "                     Description: Observed times\n",
      "                           Value: [0. 1.] d\n",
      "                  Constrained by: \n",
      "                      Constrains: None\n",
      "                      Related to: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(b['times@lc01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterSet: 2 parameters\n",
      "    ld_func@primary@lc01@dataset: logarithmic\n",
      "  ld_func@secondary@lc01@dataset: logarithmic\n"
     ]
    }
   ],
   "source": [
    "print(b['ld_func@lc01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect, if you want to pass different values to different components, simply provide them in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 22 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('lc', \n",
    "              times=[0,1], \n",
    "              ld_func={'primary': 'logarithmic', 'secondary': 'quadratic'}, \n",
    "              dataset='lc01',\n",
    "             overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterSet: 2 parameters\n",
      "    ld_func@primary@lc01@dataset: logarithmic\n",
      "  ld_func@secondary@lc01@dataset: quadratic\n"
     ]
    }
   ],
   "source": [
    "print(b['ld_func@lc01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that we didn't explicitly override the defaults for '\\_default', so they used the phoebe-wide defaults.  If you wanted to set a value for the ld_coeffs of any star added in the future, you would have to provide a value for '\\_default' in the dictionary as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterSet: 3 parameters\n",
      "  ld_func@_default@lc01@lc@da...: interp\n",
      "    ld_func@primary@lc01@dataset: logarithmic\n",
      "  ld_func@secondary@lc01@dataset: quadratic\n"
     ]
    }
   ],
   "source": [
    "print(b.filter('ld_func@lc01', check_default=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This syntax may seem a bit bulky - but alternatively you can add the dataset without providing values and then change the values individually using dictionary access or set_value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a Dataset from a File\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually from Arrays\n",
    "\n",
    "For now, the only way to load data from a file is to do the parsing externally and pass the arrays on (as in the previous section).\n",
    "\n",
    "Here we'll load times, fluxes, and errors of a light curve from an external file and then pass them on to a newly created dataset.  Since this is a light curve, it will automatically know that you want the summed light from all copmonents in the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 20 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times, fluxes, sigmas = np.loadtxt('test.lc.in', unpack=True)\n",
    "b.add_dataset(phoebe.dataset.lc, \n",
    "              times=times, \n",
    "              fluxes=fluxes, \n",
    "              sigmas=sigmas, \n",
    "              dataset='lc01',\n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enabling and Disabling Datasets\n",
    "---------------------------------------\n",
    "\n",
    "See the [Compute Tutorial](compute.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with Phases\n",
    "-------------------------------\n",
    "\n",
    "Datasets will no longer accept phases.  It is the user's responsibility to convert\n",
    "phased data into times given an ephemeris.  But it's still useful to be able to\n",
    "convert times to phases (and vice versa) and be able to plot in phase.\n",
    "\n",
    "Those conversions can be handled via [b.get_ephemeris](../api/phoebe.frontend.bundle.Bundle.get_ephemeris.md), [b.to_phase](../api/phoebe.frontend.bundle.Bundle.to_phase.md), and [b.to_time](../api/phoebe.frontend.bundle.Bundle.to_time.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dpdt': 0.0, 'period': 1.0, 't0': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(b.get_ephemeris())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(b.to_phase(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.25\n"
     ]
    }
   ],
   "source": [
    "print(b.to_time(-0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these by default use the period in the top-level of the current hierarchy,\n",
    "but accept a component keyword argument if you'd like the ephemeris of an\n",
    "inner-orbit or the rotational ephemeris of a star in the system.\n",
    "\n",
    "We'll see how plotting works later, but if you manually wanted to plot the dataset\n",
    "with phases, all you'd need to do is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.47368421  0.05263158 -0.42105263  0.10526316 -0.36842105\n",
      "  0.15789474 -0.31578947  0.21052632 -0.26315789  0.26315789 -0.21052632\n",
      "  0.31578947 -0.15789474  0.36842105 -0.10526316  0.42105263 -0.05263158\n",
      "  0.47368421  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(b.to_phase(b['times@primary@orb01']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.47368421  0.05263158 -0.42105263  0.10526316 -0.36842105\n",
      "  0.15789474 -0.31578947  0.21052632 -0.26315789  0.26315789 -0.21052632\n",
      "  0.31578947 -0.15789474  0.36842105 -0.10526316  0.42105263 -0.05263158\n",
      "  0.47368421  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(b.to_phase('times@primary@orb01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it isn't possible to attach *data* in phase-space, it is possible (**new in PHOEBE 2.2**) to tell PHOEBE at which phases to compute the model by setting `compute_phases`.  Note that this overrides the value of `times` when the model is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 20 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('lc',\n",
    "              compute_phases=np.linspace(0,1,11),\n",
    "              dataset='lc01',\n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of `compute_phases` (as well as `compute_times`) will be discussed in further detail in the [compute tutorial](./compute.ipynb) and the [advanced: compute times & phases tutorial](./compute_times_phases.ipynb).  \n",
    "\n",
    "Note also that although you can pass `compute_phases` directly to add_dataset, if you do not, it will be constrained by `compute_times` by default.  In this case, you would need to flip the constraint before setting `compute_phases`.  See the [constraints tutorial](./constraints.ipynb) and the [flip_constraint API docs](../api/phoebe.frontend.bundle.Bundle.flip_constraint.md) for more details on flipping constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParameterSet: 20 parameters | contexts: dataset, compute, constraint>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_dataset('lc',\n",
    "              times=[0],\n",
    "              dataset='lc01', \n",
    "              overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterSet: 2 parameters\n",
      "* compute_phases@binary@lc01@...: [] d\n",
      "  compute_phases@binary@lc01@...: ({compute_times@lc01@dataset} / {period@binary@component}) % 1.000000\n"
     ]
    }
   ],
   "source": [
    "print(b['compute_phases@lc01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConstraintParameter: {compute_times@lc01@dataset} = {compute_phases@binary@lc01@dataset} * {period@binary@component} (solar units) => [] d>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.flip_constraint('compute_phases', dataset='lc01', solve_for='compute_times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.set_value('compute_phases', dataset='lc01', value=np.linspace(0,1,101))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Datasets\n",
    "----------------------\n",
    "\n",
    "Removing a dataset will remove matching parameters in either the dataset, model, or constraint contexts.  This action is permanent and not undo-able via [Undo/Redo](undo_redo.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lc01', 'orb01', 'rv02', 'rv01']\n"
     ]
    }
   ],
   "source": [
    "print(b.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to remove a dataset is by its dataset tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.remove_dataset('lc01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orb01', 'rv01', 'rv02']\n"
     ]
    }
   ],
   "source": [
    "print(b.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But [remove_dataset](../api/phoebe.frontend.bundle.Bundle.remove_dataset.md) also takes any other tag(s) that could be sent to filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.remove_dataset(kind='rv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orb01']\n"
     ]
    }
   ],
   "source": [
    "print(b.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dataset Types\n",
    "------------------------\n",
    "\n",
    "For a full explanation of all related options and Parameter see the respective dataset tutorials:\n",
    "\n",
    "* [Light Curves/Fluxes (lc)](./LC.ipynb)\n",
    "* [Radial Velocities (rv)](./RV.ipynb)\n",
    "* [Line Profiles (lp)](./LP.ipynb)\n",
    "* [Orbits (orb)](./ORB.ipynb)\n",
    "* [Meshes (mesh)](./MESH.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next\n",
    "----------\n",
    "\n",
    "Next up: let's learn how to [compute observables](compute.ipynb) and create our first synthetic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
